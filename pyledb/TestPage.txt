[comment -*- outline -*- ]
[html <div class="essay_body">]

@sidebar

  How should this page be arranged? As an essay? Should it be split
  into several pages?

*** Goal

A reflective, dynamic, efficient concurrent object-orientable process
language; like SmallTalk (ST80), but as concurrent as the π calculus;
like Obliq, but with more flexible protocol. ST80 is objects all the
way down - ST-TNG should be processes (channels) all the way down,
including the frames, selectors and messages used by the
interpreter/system.

The SlateLanguage looks very interesting!

*** Objects do their own dispatch

As in SmallTalk '72, one where each receiver does its own dispatch on
the message it is sent, ST-TNG should allow the receiver to decide how
to process each individual message.

Messages in ST-TNG are [em really] messages, transmitted to the
receiving process via a real channel, received by a real channel-input
operation. The receiver is a real process, reading a message at a time
and creating replicated input by explicit recursion.

Use the Squeak (and for all I know traditional SmallTalk) technique of
hashconsing message selectors, taking the pointer to the selector,
XORing it with the pointer to the class - [em or whatever provides the
method dictionary] - and using that value as a hash into a global
method cache/memoization table.

Clever representation under the hood pops out. The
JITter/compiler/interpreter ought to be able to recognise common
patterns of send/replywait, as in the normal pattern generated by a
CPS transform. The system can optimise these special patterns. When it
sees a CPS-transformed RPC pattern it can simply make a call, without
bothering to reify the reply port. That can happen on the receiving
side, should it be considered necessary.

*** Processes all the way down

ST80 achieves objects all the way down in a couple of ways. Firstly,
the system reifies the interpreter's internal objects when
necessary. Certain primitives allow the system to get hold of the
current interpreter state. Secondly, every object is an instance of a
class, which is an object itself. The object-class-metaclass loop,
along with protocol on class [code Behaviour] allows the entire system
to inspect every aspect of itself.

So how can we get processes all the way down? We need to reify the
internal interpreter state on request, and we need to allow processes
(and channels) to describe themselves in the same way class [code
Behaviour] does in ST80. This should all be done within the standard
object protocols of the system - it shouldn't be necessary to step
outside the system to inspect it.

*** Reflection

Could reflection just be a protocol? It probably should be... that way
reflection would not step outside the system. In that case, we have a
similar setup to ST80. In ST80, bytecode is the bottom layer of the
system, and reflection etc. is built on top of that. In ST-TNG,
π-based messages would be the bottom layer, and reflection would be
built upon that.

The difficulty with reflection over π in a [em uniform] model is that
if you send a message down a channel, as you would have to to get any
reflection-type information, you alter the state of the
receiver. Unless every input is replicated, but that seems nasty. I
seem to be heading more in an Obliq direction...

Q: What if every input were replicated?

A: You can allow everything to be a real object. Even reference cells
accept 'get' and 'set:' messages as well as 'class' and other
introspection messages. Channels get protocol, too, which makes them
nonprimitive. This is a problem.

Q: What if inputs were not replicated? (with primitive channels, using
recursion for loops)

A: You can't ask what is sitting behind a channel. As soon as you send
a message, what was there has changed.

So how can we get back to primitive channels? Do we even want to?
Certainly channels make a nice framework for continuations, whether
they're primitive or not. Imagine you have a oneshot continuation
implemented like this:

@code
  [ new k.
    1 ! {k, #+, 2}.
    k ? tmp.
    Transcript show: tmp; cr. ]

Now, in order to support reflective protocol, [code k] needs to be
able to answer (!) to messages like [code #class], and to support
channel protocol (!) it needs to respond to messages like [code
#outputQueueLength], [code #inputQueueLength] etc.

@code
  [ "..."
    k = someSourceOfAOneshotContinuationChannel.
    kClass = k class.
    "..."
    k ! result. ]

which gets translated into

@code
  [ "..."
    k = someSourceOfAOneshotContinuationChannel.
    new j.
    k ! {j, #class}.
    j ? kClass.
    "..."
    k ! result. ]

The problem here is the dual role of [code !]. How about we make it
mean π-level output, and disallow it at user-level entirely? [code k]
then would be a continuation function object, just like in scheme, and
would be applied as usual for a function. (Quick, invent some function
syntax!)

@code
 x = [ y -> y + 1 ].
 x value: 123.

would be the ST80 syntax for function application. Too heavy here?

@code
  [ k ->
    kClass = k class.
    "..."
    k value: result. ] callWithCurrentContinuation.

gets translated (partway) into

@code
  [ k ->
    j = Continuation new.
    k ! {j, #class}.
    kClass = j result.
    "..."
    k ! {implicitK, #value:, result}. ] callWithCurrentContinuation.

Arrrgh! Which then becomes:

@code
  [ k ->
    j = Continuation new.
    k ! {j, #class}.
    i = Continuation new.
    j ! {i, #result}.
    kClass = i result.
    "..."
    k ! {implicitK, #value:, result}. ] callWithCurrentContinuation.

So there has to be a low-level receive in there somewhere.

@code
  [ k ->
    new j.
    k ! {j, #class}.
  LOOP:
    j ? tmp.
    (tmp primitiveAt: 1) ~= #value: => (OneShotContinuation ! tmp. LOOP).
    kClass = tmp primitiveAt: 2.
    "..."
    k ! {implicitK, #value:, result}. ] callWithCurrentContinuation.

@code
 .block anon1 (implicitK, k)
   new		j
   send		k, j, #class
 LOOP:
   recv		j, tmp
   load		tmp, 1, tmp1
   b.eq		tmp1, #value:, ISVALUE
   send		OneShotContinuation, tmp
   b		LOOP
 ISVALUE:
   load		tmp, 2, kClass
   # ...
   send		k, implicitK, #value:, result
 .end

This is making me think of a mixed functional/process model, like
Erlang, where functions, continuations and bytecode-blocks are just as
primitive as channels and processes. How would that look?

Actually, even ST80 isn't completely "honest" behind the scenes - if
it really had to construct a [code Message] for each message-send, it
would get stuck trying to construct the message to construct the
message to construct... etc.!

It does look like a processes-all-the-way-down view is incompatible
with built-in reflection, unless there are two kinds of messages - or,
intriguing idea, you're allowed to lift the process behind a port into
a message!

**** Reifying processes

A separate match operator from comm, so that we don't have to
introduce any kind of sum. A lift operator and corresponding drop
operator. Somehow want *objective* lift, as opposed to the subjective
lift in Greg's [html &rho;]-calculus. (cf. \[CG03\])

Interesting to consider an ambient as a process or thread
group. Perhaps objective-lift could be applied to an entire ambient?

@sidebar
  Is this the right name for the problem?
Apparently you have to be careful with ambient calculi, since some
forms can encode a solution to the leaderless election problem.

**** Reifying interpreter state

This falls out of reifying processes, no?

*** A process language with locations and reflection

**** Basic Object Engine

Regarding continuations, applications and conditionals are the only
things to worry about - conditionals only because of the 'next step'
involved in testing the result of the test-expression.

If conditionals were rewritten in the form of

@code
   (testexpr) ifTrue: [true code] ifFalse: [false code]

ie. with explicit lambdas, there would only be one rule.

This brings us to the fact that continuations are only required when
evaluating actual parameter expressions. In s-exprs,

@code scheme
   (f a b c)

and in ST-like syntax

@code
   f with: a with: b with: c

A continuation is required for each of f, a, b, c that
are *non-simple*.

Let a continuation be a special procedure, likely a primitive, that
has a reference to a chain of frames. Then we define a frame to be a
copy of the active machine registers:

@code c
  acc;		/* Accumulator 					object */
  ip;		/* Instruction pointer				integer */
  stack;	/* Stack					vector */
  top;		/* Top of stack (ascending, empty)		integer */
  frame;	/* Frame stack					vector */
  closure;	/* The closure that this frame is executing	object */

and a closure consists of:

@code c
  env;		/* Environment					vector */
  callable;	/* Code this closure closes over		object */

and a callable consists of:

@code c
  stacklen;	/* Number of stack slots required		integer */
  code;		/* Code block					bytevector */
  lits;		/* Literal table				vector */
  source;	/* Source code string				object */

@sidebar

  This discussion of objects vs ST-objects is very shaky. I want
  somehow to get across the point that the only things that exist are
  objects, but that every object is a channel, and that not every
  object has ST80-like dispatch behaviour associated with it.

We distinguish between objects, a small, closed group of meta-level
types that taken together with 'lift' and 'drop' procedures suffice to
describe the entire image, and ST-objects, an unbounded group of
object-level types that implement a well-known message dispatch
protocol.

Let calls and returns be represented directly. Since calls and returns
are notionally message send/receive pairs on channels, we have that
each closure and each channel must be able to act in a dual role.

Recall from π encodings of lambda that a closure is a channel with a
single replicated reader process attached to it.

  - send to a closure: schedule the invocation of the closure, and the
    capture and transmission of the result to the passed-in
    continuation. If the message isn't the right shape, signal an
    error in the sender's dynamic environment.

  - send to a channel: usual behaviour (scheduling of the
    continuation) if there's a reader waiting, otherwise enqueue the
    message.

  - read from a channel: suspend the current thread on the channel,
    unless there's a message waiting, in which case consume it and
    move on.

Primitives obviously need to act more-or-less like closures. The
implementation can represent these specially.

**** The Process Calculus

Locations are nested, like ambients. Channels are restricted with
normal scope extrusion. Communication happens between locations
transparently - any unguarded receive and any unguarded send on the
same channel will occur, no matter the structure of the ambients
involved.

Locations are the unit of reflection granularity. Locations can be
lifted to a description of the corresponding collection of processes,
and such a description can be dropped to instantiate the described
processes. Locations are written

@code
  m[P]

where 'm' is a channel acting as a 'location tag' for this location.

Processes P, Q:

@code
	0		stop
	(x)P		new
	P | Q		parallel composition
	µA.P		process variable binding
	A		process variable reference
	x<M>		output
	x(M).P		input
	x[P]		location
	lift x		lift
	drop x		drop (aka eval)

Messages M are a possibly empty sequence of names.

Structural equivalence:

@code
  m[P] | m[Q]   ===   m[P | Q]
      m[x<M>]   ===   x<M>
    m[lift x]   ===   lift x
         m[0]   ===   0

Reduction:

@code
      m not used as a location tag in Q
  -------------------------------------------
    m[P] | Q | lift m   -->   Q | LIFT(m,P)

where LIFT(m,P) expands into a process description of the process P,
the channel for interfacing to which is placed on the channel m.


@code
       P   -->   P'
  ----------------------
    m[P]   -->   m[P']

@code
  --------------------------
    drop x   -->   DROP(x)

where DROP(x) expands into a process which examines the process
description of a process P that answers to requests on channel x, and
instantiates P.

Note that lift and drop are asymmetric: lift collects the description
for an entire location, but drop instantiates the provided description
into the current location.

Note also that output and lift are continuationless and may freely
move between locations, where input and drop have continuations
(implicit, in the case of drop) and may not leave the confines of
their location. Messages (names) are thus mobile, while processes are
immobile without explicit use of lift and drop.


**** Uses of Lift

Lift can be used to interrupt a running collection of processes for
inspection in an interactive debugger:

@code
  m[P] | lift m | m(p).debuggerFactory<"breakpoint",p>

Lift can (sort-of) be used for error handling - each location can be
used as a 'catch' to which the error condition is 'thrown':

@code
  m[P | m<"error description">]  |  m(e).(lift m | m(p).debuggerFactory<e,p>)

Nested handlers can be defined:

@code java
  try {
    CODE
  } catch (e, p) {
    HANDLER
  }

becomes:

@code
  (exn)( exn[CODE] | exn(e).(lift exn | exn(p).HANDLER) )

so long as

@code java
  throw e

is encoded as

@code
  exn<e>

for the innermost defined 'exn' name. See below for some problems with
this approach.

**** Variants and challenges

***** Try/Finally clauses

"try/finally" clauses are a challenge, since [code m[0] === 0] and we
want to detect when [code m[]] has 'stopped'. One way around it might
be to change the syntax for processes to have instead

@code
	x[P].Q

for locations, with an altered structural equivalence:

@code
  m[P].Q | m[P'].Q'   ===   m[P | P'].(Q | Q')
          m[x<M>].P   ===   m[0].P | x<M>
        m[lift x].P   ===   m[0].P | lift x
             m[0].P   =/=   0   (this rule is replaced by a new reduction relation)

and altered reduction rules:

@code
         m not used as a location tag in Q
  -------------------------------------------------
    m[P].P' | Q | lift m   -->   Q | LIFT(m,P,P')

where LIFT(m,P,P') expands into a process description of the processes
P and P', the channels for interfacing to which (p and p'
respectively) are placed on the channel m as: [code m<p,p'>]


@code
         P   -->   P'
  --------------------------
    m[P].Q   -->   m[P'].Q


@code
    m not used as a location tag in Q
  -------------------------------------
        m[0].P | Q   -->   P | Q

***** Dynamic environments

The current exception handler ('exn' above) is a dynamically-scoped
entity in most languages, but in the discussion of error-handling
above it is [i lexical] since there is no clear notion of dynamic
scope. This is unacceptable for use as an error-reporting mechanism.

Note that the current continuation is a dynamic entity as well! Since
the current continuation is explicitly passed around in encodings of
lambda calculi into π, there's nothing stopping us passing around
arbitrary other dynamic entities at the same time, so long as our
encoding is uniform. This would give rise to a [code
call-with-current-exception-handler] by analogy with [code
call-with-current-continuation].

Traditional continuation-passing-style:

@code scheme
  (lambda (x) (+ x 1))   -->   (lambda (k x) (+ k x 1))

Extended continuation-and-exception-handler-passing-style:

@code scheme
  (lambda (x) (+ x 1))   -->   (lambda (k h x) (+ k h x 1))

This could be generalised to a (perhaps implicit at the implementation
level) collection of arbitrary dynamic state.

***** Error or exception reporting, revisited

A dynamic-extent error-reporting channel can be combined with the use
of [code lift] to give a more acceptable form of exception
handling. When throwing an exception, care must be taken to select an
appropriate channel; procedural code can use [code
call-with-current-error-channel] of course, but raw process code needs
to be more explicit about the target of the thrown exception.

There are still a few issues: "stack traces" are still missing from
the picture, for instance. An exception thrown by some library code in
a different lexical scope will have to be careful to provide
self-describing restarts as part of the error report message sent down
the error-reporting channel at the time of the throw. This is
straightforward in a procedural situation, but in the general case it
is less obvious how to do this.

One approach might be for each ongoing computation to be partitioned
into a fresh location:

@code
  µLOOP .
    service(k,h,message) .
      LOOP |
      (loc) loc[ BODY OF SERVICE |
                 h<"error description", k, loc> ])

When an error is signalled, the location can be passed (with some
suitable self-describing convention) along with the error report to
the waiting handler on the other side of the report channel. The
location need not be lifted at the time of the throw; whether it was
lifted at all might be a policy decision made by the error-report
receiver at the other side. Often the location might be lifted into
the debugger along with the location that sent the message to the
library code that caught the error.

***** Capabilities

Channels, so long as they are unforgeable, can be used as capabilities
in a few different ways. One relies on an equivalence relation between
names and a comparison process

@code
  [x=y]{P,Q}

which reduces to [code P] if [code x] and [code y] are the same name,
and [code Q] otherwise. Names (without processes attached to them
necessarily) can then be used as permissions.

The dynamic environment idea detailed above can then be used to carry
around a collection of permissions. A function [code
call-with-current-permission-map] can be provided, allowing a dynamic
permissions check in server code. Some means of replacing the current
permission map within a piece of code can also be provided, allowing
code to enlarge or reduce its permission map within some scope.

***** A variation on comm

The current comm rules (implied above) are not well pinned down since
there's a structural equivalence rule equating [code m[x<M>]] with
[code x<M>]. This means that [code lift m] may or may not capture the
output on [code x].

We need some way of forcing unguarded sends out of a location at the
time of lifting that location. One way to approach that might be to
redefine the lift operation to partition the location's contents:

@code
         m not used as a location tag in Q
       no sends on any channel unguarded in P
  -------------------------------------------------
    m[P].P' | Q | lift m   -->   Q | LIFT(m,P,P')

[b Alternative:] there are still problems, since now outputs are
opaque to the reflection primitive, lift. A better way might be to try
to attach the output messages to the restriction itself, thus
modelling the message queue directly. The problem then is making any
unguarded inputs find the messages from the relevant restriction!

***** Dynamic Environments of a different kind

To get lookup on "local services" (eg. java.lang.String etc) perhaps
lift and drop should be augmented with a second argument: ports equal
(via name equality) to this argument would be replaced with a special
piece of syntax in the lift, and in the drop, the special piece of
syntax would be replaced with the value of the argument. This lets you
provide eg. a sandbox environment or whatever.


**** Integrating lambda with π

See also the "blue calculus" by G. Boudol.

Thinking about evaluating Scheme using an operational semantics:
evaluate each position in a combination until the positions are values
rather than expressions. Then apply the combination.

@code scheme
  (let ((x (lambda (y) (+ y 1))))
    (x (x 2)))
  ;==> macroexpands to
  ((lambda (x) (x (x 2)))
   (lambda (y) (+ y 1)))
  ;-->
  ((lambda (y) (+ y 1)) ((lambda (y) (+ y 1)) 2))
  ;-->
  ((lambda (y) (+ y 1)) (+ 2 1))
  ;-->
  ((lambda (y) (+ y 1)) (#<primitive+> 2 1))
  ;-->
  ((lambda (y) (+ y 1)) 3)
  ;-->
  (+ 3 1)
  ;-->
  (#<primitive+> 3 1)
  ;-->
  4

***** Syntax

Recommend an A-normal form - [code let x = M N in x] (??) - to provide
linear form. Note that's a let, not a letrec. I guess this is pretty
similar to Boudol's Blue Calculus?

Also, how about Matthias' well-formedness constraint to ensure
appropriate use of input capability? How does the input capability
move with lift and drop? Does the location for the port move with the
process??

Processes P, Q:

@code
	0		stop
	(x)P		new
	P | Q		parallel composition
	µA.P		process variable binding
	A		process variable reference
	x<M>		output
	x(M).P		input
	x[P].Q		location
	lift x		lift
	drop x		drop (aka eval)

Messages <M>:

Bindings (M):

Expressions E, F:

Values V, W are 

The rules, then, are

@code
  \x . 

*** Encoding 'become:'

Smalltalk's [code #become:] message can be implemented at the process
level by specifying protocol for telling a repeated-read to unhook
itself. Once the channel is separated from its process a new process
can be attached. This only works of course if the slots are kept
separately from the channel.

*** Scheduling

The scheduler can do the traditional timeslicing thing if there is
real parallelism. Once a sequential "thread" is over, the scheduler
regains control automatically of course and can simply pop the next
item off the work queue and keep on trucking sequentially.

When the scheduler runs out of work, that means the system has
quiesced. Is it just waiting for an interrupt (user/network/disk
activity), or has it deadlocked somewhere?

*** SMP

SMP systems ought to communicate via message passing rather than
shared memory. Each CPU becomes a real separate network-linked compute
resource. Display and peripherals I guess have to be split across the
SMP machine somehow - process migration? Object cloning, a la Obliq?

The representation of channels will be interesting. Since we don't
have SMP to worry about, we don't need to lock - [em ever] - so
placing a (pseudo-) message on a channel is as simple as arranging the
message and calling the function-pointer held within the channel
itself!

*** Experimental toy syntax examples

@code
  <class> methods at: #subClass:instanceVariables:classVariables: put:
    [ self aName ivars cvars ->
      n = self class new.
      n super: self.
      n printName: aName.
      n instanceVariables: ivars.
      n classVariables: cvars.
      n ].

  <class> methods at: #inheritanceChain put:
    [ self ->
      cond super isNil => nil
         | super :: super inheritanceChain ]

  <class> methods at: #writeOn: put:
    [ self port -> {'#<class ', self printName, '>'}
                     sequence: [ x -> port display: x ] ].

  <class> methods at: #displayOn: put:
    [ self port -> self writeOn: port ].

  <object> methods at: #dissect put:
    [ self -> self dissectOn: System stdout ].

  <object> methods at: #isInstanceOf: put:
    [ self aClass ->
      loop = [ c ->
               cond c isNil => False
                  | c == aClass => True
                  | loop (c super) ].
      loop (self class) ].

@code
  !<object> methodsFor: 'printing'
  !dissectOn: port

      print = [ x -> port display: x ].

      {'An instance of class ', self class printName, '.\n',
       'Instance variables:\n'}
        sequence: print.

      loop = [ class ->
               cond class isNil => nil
                  | class == <object> => nil
                  | ({'--------', class printName, '\n'} sequence: print.
                     class instanceVariables sequence:
                       [ ivar ->
                         {'\t', ivar, '\t\t', self instanceVariableAt: ivar, '\n'}
                           sequence: print ].
                     loop (class super)) ].
      loop (self class)
  !!

*** Unfiled from 8020

For objects, or object-like structures, the functionpointer will
process the message efficiently in order to determine the intended
method, and will then pass the details on to the method closure. For
anything else, the functionpointer will simply place the message on a
queue if there's no receiver waiting. If there is a receiver waiting,
it might be an RPC-style receiver in which case another simple stack
based call can be made; alternatively the continuation can be hooked
up with the message and scheduled normally for the scheduler to get to
in its own good time. At every level, the common-case pattern can be
optimised with robust fallbacks for the less usual cases.

For the common case of a method-call-style-message-send-and-replywait,
neither the message nor the reply port need be eagerly
constructed. The calling convention for channel functionpointers has
it so that on entry to the functionpointer, if a certain register is
zero, say, then the message and waiting continuation are implicit in
the parameter registers and the waiting stack frame. Should they need
reifying, it's obvious where to look and how to go about it;
otherwise, let them stay implied, and when the reply appears for the
continuation, simply do a stack return as usual for a sequential
language. If the special register was nonzero, then a real message
would be waiting and the system would fall back to a slower but more
general message delivery and rendezvous implementation. This lets
sequential code run sequentially.

Almost everything can be done late. As Alan Kay puts it in "The Early
History of SmallTalk", "The art of the wrap is the art of the
trap". Treat the common case as the fast path and trap on any
deviation from the norm. Clever use of indirection and function
pointers, combined with the metaphor of the receiver doing its own
dispatching (which applies at multiple levels here - not only at the
language metaphor level but also in terms of implementation details,
with the channel semantics being represented by a functionpointer) can
help automatically trap a lot of the time without special hardware
support.

A note on these functionpointers: replicated input RPC-style
processes, ie. [i functions] (closures) can be efficiently represented
as channels with a functionpointer that does the work of the closure!
No message passing overhead at all! Note also that this applies
equally to primitives as to user blocks (in the sense of a SmallTalk
block, aka a lambda term).

What about image saving? EROS style checkpointing? Can we get that
reliable, efficiently? Have a small "emergencies-only" image in case
you corrupt your mainline image... signed primitives can come in over
the net and be installed by the user based on a web of trust... if you
upgrade your CopyBits, and it starts crashing, boot into the
emergency-only image and repair the damage.

Object models! The system supports traditional SmallTalk style class-
(and metaclass-) based dispatch, but it [em equally efficiently]
supports Self- or Javascript-like prototype object dispatch, or
Python-like class-based dispatch etc etc. Scheme/Lisp-style objects
based on closures can also be efficiently represented. An annotation
on code as a hint to the interpreter/JIT that a certain RPC can be
memoised weakly (ie. in the global method cache) is sufficient for all
these forms of dispatch. The one thing missing is multimethod dispatch
- how might that work? The Slate project at [code tunes.org] might
have some literature on this.

How can conditionals be efficiently compiled? How does SmallTalk
detect when [code #ifTrue:ifFalse:] hasn't been reimplemented in the
receiver? There's special bytecode for conditional jumps in
Squeak.

 - the answer to this is "the art of the wrap is the art of the
   trap". The compiler can assume that [code #ifTrue:ifFalse:] is
   going to run against [code Boolean]s, and the runtime just makes a
   quick check before doing the optimised thing. It has its work cut
   out for it if the receiver is a non-[code Boolean]: it has to
   construct the two blocks and hand them off in the official way to
   the receiver.

Object representation - cons up whole vectors of fresh channels at
once. These are used for instance variables.

*** Operating System Issues

I agree with Alan Kay and Dan Ingalls in their statements that the
operating system is for all the things you can't express in your
language - and thus that there shouldn't be one. The language and its
environment should be so inseparable and all-encompassing that they
are the only environment for the use of the computer. With that in
mind, I've written some notes on ImplementingTcp.

*** References

External links about SmallTalk, the language and its implementation:

 - http://users.ipa.net/~dwighth/smalltalk/byte_aug81/design_principles_behind_smalltalk.html
 - http://www.laputan.org/ref89/ref89.html
 - http://users.ipa.net/~dwighth/smalltalk/bluebook/bluebook_imp_toc.html

Concurrent SmallTalk:

 - http://cva.stanford.edu/j-machine/cva_j_machine.html
 - [attachment revised-concurrent-smalltalk-manual.pdf]
 - [attachment yaacob-thesis.pdf]

π-Calculi and Ambient calculi:

 - \[CG03\] Cardelli, Luca and Gordon, Andrew D.: [i "Mobile Ambients"], 2003.

Links to my and [code mikeb]'s writing:

 - On [link http://www.eighty-twenty.org/index.cgi/tech/smalltalk/index.html|eighty-twenty.org]
   ([link http://localhost/~tonyg/8020-generated/index.cgi/tech/smalltalk/index.html|local mirror])


[html </div>]
